setup:
  runner: train_dpdm_base
  n_gpus_per_node: 2
  n_nodes: 1
  node_rank: 0
  master_address: '127.0.0.1'
  master_port: 6020
  omp_n_threads: 4
data:
  path: /bigtemp/fzv6en/datasets/celeba_64.zip
  name: celeba_64
  num_channels: 3
  resolution: 64
  n_classes: null
  fid_stats: 
  - /bigtemp/fzv6en/datasets/celeba_64.npz
  dataloader_params:
    num_workers: 2
    pin_memory: True
  dataset_params:
    use_labels: False
model:
  ckpt: /bigtemp/fzv6en/kecen0923/DDPM/pretrain_celeba_64_top10_e0.001_png/checkpoints/snapshot_checkpoint.pth
  denoiser_name: edm
  denoiser_network: song
  ema_rate: .999
  network:
    ch_mult: [1, 1, 2, 2]
    image_size: 64
    num_in_channels: 3
    num_out_channels: 3
    label_dim: 0
    use_cfg: False
    attn_resolutions:
    - 8
    - 16
optim:
  optimizer: Adam
  params:
    lr: 3e-4
    weight_decay: 0.
sampler:
  type: ddim
  stochastic: False
  num_steps: 50
  tmin: .002
  tmax: 80.
  rho: 7.
  guid_scale: 0.
  snapshot_batch_size: 64
  fid_batch_size: 64
  labels: null
train:
  seed: 0
  batch_size: 8192
  n_epochs: 50
  log_freq: 100
  snapshot_freq: 1000
  snapshot_threshold: 1
  save_freq: 100000
  save_threshold: 1
  fid_freq: 10000
  fid_samples: 5000
  fid_threshold: 1
loss: 
  version: edm
  p_mean: -1.2
  p_std: 1.2
  n_noise_samples: 8
dp:
  max_grad_norm: 0.001
  delta: 8e-7
  epsilon: 9.999
  max_physical_batch_size: 2048
  n_splits: 64